{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils as utils\n",
    "import utils.datasets as datasets\n",
    "\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, input_data = datasets.casme2(resize=64, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 256/256 [01:49<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "pr_frames = [video for video in tqdm(input_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEGC(Dataset):\n",
    "    def __init__(self, frames, labels, transform=None):\n",
    "        self.frames = frames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.frames[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_W(T, alpha=20, r1=0.4, r2=0.05):\n",
    "    W = torch.zeros(T, T, dtype=torch.float).to(device)\n",
    "    #construct W\n",
    "    for i in range(T):\n",
    "        for j in range(T):\n",
    "            a = j - i\n",
    "            b = min(1, i)\n",
    "            if j > i:\n",
    "                W[i, j] = alpha * (1 - r1) ** a * r1 ** b - alpha * (1 - r2) ** a * r2 ** b\n",
    "            elif j == i:\n",
    "                W[i, j] = alpha * (r1 - r2)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def led(x, W):\n",
    "    s, f, c, h, w = x.shape\n",
    "    out = torch.einsum(\"sfchw,fx->sxchw\", x, W)\n",
    "    div = torch.einsum(\"sfchw,fx->sxchw\", x, torch.abs(W))\n",
    "    out /= div + 1\n",
    "    out[:, 0] = x[:, 0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, task_num, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.task_num = task_num\n",
    "        h1 = 32\n",
    "        h2 = 64\n",
    "        h3 = 256\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=h1, kernel_size=(1, 5, 5), stride=1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 3, 3))\n",
    "        self.bn1 = nn.BatchNorm3d(h1)\n",
    "        self.drop1 = nn.Dropout3d(dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(in_channels=h1, out_channels=h2, kernel_size=(2, 3, 3), stride=1)\n",
    "        self.bn2 = nn.BatchNorm3d(h2)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.drop2 = nn.Dropout3d(dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(9 ** 2 * 2 * h2, h3)\n",
    "        self.fcs = nn.ModuleList([nn.Linear(h3, 2) for _ in range(self.task_num)])\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.log(torch.tensor(10.0)))\n",
    "        self.r1 = nn.Parameter(torch.log(torch.tensor(0.4)))\n",
    "        self.r2 = nn.Parameter(torch.log(torch.tensor(0.05)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W = calculate_W(6, torch.exp(self.alpha), torch.exp(self.r1), torch.exp(self.r2)).to(device)\n",
    "        x = led(x, W)\n",
    "        x = x[:, 1:]\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "     \n",
    "        x = self.drop1(self.bn1(self.pool(F.relu(self.conv1(x)))))\n",
    "        x = self.drop2(self.bn2(self.pool2(F.relu(self.conv2(x)))))\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop3(x)\n",
    "        xs = [fc(x) for fc in self.fcs]\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskF1(nn.Module):\n",
    "    def __init__(self, task_num):\n",
    "        super(MultiTaskF1, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        \n",
    "    def calc_f1(self, label, prediction):\n",
    "        _, predicted = torch.max(prediction, 1)\n",
    "        f1 = f1_score(label.cpu(), predicted.detach().cpu(), average=\"macro\")\n",
    "        return f1\n",
    "                        \n",
    "    def forward(self, preds, labels):\n",
    "        f1s = [self.calc_f1(labels[:, i], preds[i]) for i in range(self.task_num)]\n",
    "        return f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transform(video):\n",
    "    n_frames = 6\n",
    "    max_f = np.random.randint(n_frames, video.shape[0] - 1)\n",
    "    idx = np.round(np.linspace(0, max_f, n_frames)).astype(\"int\")\n",
    "    video = video[idx]\n",
    "    video = np.expand_dims(video, 1)\n",
    "    return video\n",
    "\n",
    "def test_transform(video):\n",
    "    n_frames = 6\n",
    "    idx = np.round(np.linspace(0, video.shape[0] - 1, n_frames)).astype(\"int\")\n",
    "    video = video[idx]\n",
    "    video = np.expand_dims(video, 1)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSO(features, df, action_units, epochs=200, lr=0.01, batch_size=128, dropout=0.05, weight_decay=0.001):\n",
    "    random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    torch.cuda.manual_seed(1)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    labels = np.concatenate([np.expand_dims(df[au], 1) for au in action_units], axis=1)\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    for group in df.groupby(\"subject\"):\n",
    "        subject = group[0]\n",
    "        #Split data\n",
    "        train_index = np.array(df[df[\"subject\"] != subject].index)\n",
    "        X_train = [features[i] for i in train_index]\n",
    "        y_train = labels[train_index]\n",
    "        \n",
    "        test_index = np.array(df[df[\"subject\"] == subject].index)\n",
    "        X_test = [features[i] for i in test_index]\n",
    "        y_test = labels[test_index]\n",
    "        \n",
    "        megc_dataset_train = MEGC(X_train, y_train, train_transform)\n",
    "        dataset_loader_train = torch.utils.data.DataLoader(megc_dataset_train,\n",
    "                                                             batch_size=batch_size, shuffle=True,\n",
    "                                                             num_workers=0)\n",
    "\n",
    "        megc_dataset_test = MEGC(X_test, y_test, test_transform)\n",
    "        dataset_loader_test = torch.utils.data.DataLoader(megc_dataset_test,\n",
    "                                                         batch_size=100, shuffle=False,\n",
    "                                                         num_workers=0)\n",
    "        \n",
    "        net = Net(labels.shape[1], dropout=dropout).float().to(device)\n",
    "        criterion = utils.MultiTaskLoss(labels.shape[1])\n",
    "        evaluation = MultiTaskF1(labels.shape[1])\n",
    "        optimizer = optim.Adam([{\"params\": list(net.parameters())[:3], \"lr\": 0.1},\n",
    "                                {\"params\": list(net.parameters())[3:]}\n",
    "                               ], lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "            vals.append([net.alpha.item(), net.r1.item(), net.r2.item()])\n",
    "            if epoch == 50:# or epoch == 100:# or epoch == 200:\n",
    "                optimizer.param_groups[0][\"lr\"] *= 0.1\n",
    "                pass\n",
    "            for batch in dataset_loader_train:\n",
    "                data_batch, labels_batch = batch[0].to(device), batch[1].to(device)\n",
    "                #data_batch = transform(data_batch)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(data_batch.float())\n",
    "                loss = criterion(outputs, labels_batch.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        #eval\n",
    "        net.eval()\n",
    "        data_batch_test, labels_batch_test = dataset_loader_test.__iter__().__next__()\n",
    "        data_batch_test = data_batch_test.to(device)\n",
    "        outputs = net(data_batch_test.float())\n",
    "        outputs_list.append([output.cpu().detach() for output in outputs])\n",
    "        labels_list.append(labels_batch_test)\n",
    "        train_outputs = net(data_batch.float())\n",
    "        net.train()\n",
    "        f1_train = evaluation(train_outputs, labels_batch.long())\n",
    "        f1 = evaluation(outputs, labels_batch_test.long())\n",
    "        print(f\"Alpha: {torch.exp(net.alpha)}, r1: {torch.exp(net.r1)}, r2: {torch.exp(net.r2)}\")\n",
    "        print(\"Subject: {}, n={} | train_f1: {:.5} | test_f1: {:.5}\".format(\n",
    "            subject, str(data_batch_test.__len__()).zfill(2), np.mean(f1_train), np.mean(f1)))\n",
    "    #Calculate total f1-scores\n",
    "    predictions = torch.cat([torch.tensor([torch.max(i, 1)[1].tolist() for i in outputs_list[i]]).T\n",
    "                   for i in range(outputs_list.__len__())])\n",
    "    labels = torch.cat(labels_list)\n",
    "    f1_aus = [f1_score(predictions[:, i].cpu(), labels[:, i].cpu().data.numpy(), average=\"macro\")\n",
    "              for i in range(labels.shape[1])]\n",
    "    f1_aus_binary = [f1_score(predictions[:, i].cpu(), labels[:, i].cpu().data.numpy(), average=\"binary\")\n",
    "                     for i in range(labels.shape[1])]\n",
    "    print(\"All AUs: \",list(zip(action_units, f1_aus)))\n",
    "    print(\"Mean f1: \", np.mean(f1_aus))\n",
    "    print(\"Binary f1: \", np.mean(f1_aus_binary))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0997099056839943, r1: 0.23313838243484497, r2: 0.20474375784397125\n",
      "Subject: 01, n=09 | train_f1: 0.9908 | test_f1: 0.86351\n",
      "Alpha: 0.642595648765564, r1: 0.05875437334179878, r2: 0.4094427824020386\n",
      "Subject: 02, n=13 | train_f1: 0.98708 | test_f1: 0.83969\n",
      "Alpha: 0.9148291945457458, r1: 0.09491778165102005, r2: 0.37089040875434875\n",
      "Subject: 03, n=07 | train_f1: 0.98308 | test_f1: 0.80379\n",
      "Alpha: 0.4587725102901459, r1: 0.10528364032506943, r2: 0.3440375328063965\n",
      "Subject: 04, n=05 | train_f1: 1.0 | test_f1: 0.97024\n",
      "Alpha: 0.5086752772331238, r1: 0.09204389899969101, r2: 0.3171556890010834\n",
      "Subject: 05, n=19 | train_f1: 1.0 | test_f1: 0.79549\n",
      "Alpha: 1.0054630041122437, r1: 0.09224669635295868, r2: 0.39841228723526\n",
      "Subject: 06, n=05 | train_f1: 0.99644 | test_f1: 0.80159\n",
      "Alpha: 1.3133655786514282, r1: 0.06624402105808258, r2: 0.4578610062599182\n",
      "Subject: 07, n=09 | train_f1: 0.9978 | test_f1: 0.79072\n",
      "Alpha: 0.8313130736351013, r1: 0.08014599978923798, r2: 0.37342938780784607\n",
      "Subject: 08, n=03 | train_f1: 1.0 | test_f1: 0.80833\n",
      "Alpha: 0.9684985876083374, r1: 0.15522266924381256, r2: 0.29872414469718933\n",
      "Subject: 09, n=14 | train_f1: 0.9922 | test_f1: 0.79487\n",
      "Alpha: 0.7032148241996765, r1: 0.09019368886947632, r2: 0.380680650472641\n",
      "Subject: 10, n=14 | train_f1: 1.0 | test_f1: 0.84704\n",
      "Alpha: 0.030619695782661438, r1: 0.4001636803150177, r2: 0.1025986447930336\n",
      "Subject: 11, n=10 | train_f1: 0.99673 | test_f1: 0.97549\n",
      "Alpha: 0.8860659599304199, r1: 0.07982813566923141, r2: 0.41688331961631775\n",
      "Subject: 12, n=12 | train_f1: 0.99002 | test_f1: 0.90229\n",
      "Alpha: 0.549472451210022, r1: 0.06922592222690582, r2: 0.28973016142845154\n",
      "Subject: 13, n=08 | train_f1: 1.0 | test_f1: 0.98182\n",
      "Alpha: 0.8050634860992432, r1: 0.07393669337034225, r2: 0.47213420271873474\n",
      "Subject: 14, n=04 | train_f1: 0.98494 | test_f1: 0.93333\n",
      "Alpha: 0.10000021755695343, r1: 0.22764797508716583, r2: 0.21158219873905182\n",
      "Subject: 15, n=03 | train_f1: 0.99594 | test_f1: 0.85\n",
      "Alpha: 0.9505752325057983, r1: 0.07690712809562683, r2: 0.38722240924835205\n",
      "Subject: 16, n=04 | train_f1: 0.9955 | test_f1: 0.9\n",
      "Alpha: 0.9909258484840393, r1: 0.08214833587408066, r2: 0.39504775404930115\n",
      "Subject: 17, n=36 | train_f1: 1.0 | test_f1: 0.92981\n",
      "Alpha: 0.462257444858551, r1: 0.09225329011678696, r2: 0.3019234836101532\n",
      "Subject: 18, n=03 | train_f1: 1.0 | test_f1: 1.0\n",
      "Alpha: 0.9696822166442871, r1: 0.07293252646923065, r2: 0.4674694836139679\n",
      "Subject: 19, n=16 | train_f1: 1.0 | test_f1: 0.8455\n",
      "Alpha: 2.0444440841674805, r1: 0.0844886377453804, r2: 0.4875265657901764\n",
      "Subject: 20, n=11 | train_f1: 1.0 | test_f1: 0.80053\n",
      "Alpha: 0.034146662801504135, r1: 0.1664443463087082, r2: 0.08479945361614227\n",
      "Subject: 21, n=02 | train_f1: 0.99782 | test_f1: 0.83333\n",
      "Alpha: 1.2487120628356934, r1: 0.08378104865550995, r2: 0.40791866183280945\n",
      "Subject: 22, n=02 | train_f1: 0.99273 | test_f1: 1.0\n",
      "Alpha: 0.7345356941223145, r1: 0.09092928469181061, r2: 0.4630039930343628\n",
      "Subject: 23, n=12 | train_f1: 0.99815 | test_f1: 0.78263\n",
      "Alpha: 0.011573958210647106, r1: 0.3303886950016022, r2: 0.08302474766969681\n",
      "Subject: 24, n=11 | train_f1: 0.99699 | test_f1: 0.92869\n",
      "Alpha: 0.8023251891136169, r1: 0.08259230852127075, r2: 0.40276026725769043\n",
      "Subject: 25, n=07 | train_f1: 0.99636 | test_f1: 0.73816\n",
      "Alpha: 1.4903430938720703, r1: 0.06610740721225739, r2: 0.43420225381851196\n",
      "Subject: 26, n=17 | train_f1: 0.9903 | test_f1: 0.88091\n",
      "All AUs:  [('AU1', 0.9378942261038332), ('AU2', 0.8372881355932204), ('AU4', 0.9179374456198196), ('AU7', 0.7063799283154122), ('AU12', 0.8392857142857142), ('AU14', 0.7856040904482743), ('AU15', 0.8379233934789491), ('AU17', 0.826854983091307)]\n",
      "Mean f1:  0.8361459896170662\n",
      "Binary f1:  0.7133139709614811\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "action_units = [\"AU1\", \"AU2\", \"AU4\", \"AU7\", \"AU12\", \"AU14\", \"AU15\", \"AU17\"]\n",
    "predictions = LOSO(pr_frames, df, action_units, epochs=400, lr=0.0001, weight_decay=0.001,\n",
    "     dropout=0.5, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
